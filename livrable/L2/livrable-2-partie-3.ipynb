{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036a3dc9",
   "metadata": {},
   "source": [
    "## **1. OBJECTIFS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3499e06",
   "metadata": {},
   "source": [
    "Nous voulons évaluer rigoureusement la robustesse de notre modélisation et notre implémentation au-delà de sa seule validité théorique et sa faisabilité technique. Dans quelles conditions notre approche produit-elle des solutions de bonne qualité en un temps de calcul raisonnable ? Avec quelle variabilité ? Comment se comporte l'algorithme au cours de sa recherche, et qu'est ce qui explique son succès où son échec ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa08f85",
   "metadata": {},
   "source": [
    "Cette étude vise ainsi à établir la viabilité de notre solution à travers une **évaluation empirique** complète, en se reposant sur des benchmarks standardisés, des analyses statistiques et une lecture comportementale. Elle soulève les questions suivantes :  \n",
    "- Qualité : l'écart relatif à un optimum connu et le respect strict des contraintes\n",
    "- Robustesse : la variabilité et la part de l'aléatoire entre différentes exécutions des algorithmes, ainsi que la sensibilité aux paramètres et aux changements\n",
    "- Scalabilité : la façon dont le temps d'exécution et de l'écart à l'optimum évoluent lorsque la taille des données d'entrée et la difficulté des instances croissent.\n",
    "- Comportement : la trajectoire et l'équilibre entre l'intensification et la diversification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf03cce-cc60-4659-99fc-11760676a300",
   "metadata": {},
   "source": [
    "Pour y répondre, nous mettrons en œuvre un **plan d'expériences** (Design of Experiments - **DoE**). Cette approche méthodologique permet d'étudier l'effet de multiples facteurs (les paramètres de notre algorithme, les données d'une instance) sur les indicateurs de performance. Plutôt que de faire varier un seul paramètre à la fois, un plan d'expériences nous permettra d'identifier efficacement les facteurs les plus influents, de quantifier leur impact et de déceler d'éventuelles interactions entre eux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04a5e0",
   "metadata": {},
   "source": [
    "Afin de garantir toute reproductibilité et transparence, nous fourniront le plus de détail possible sur l'environnement utilisé, les graines d'aléatoire, les temps limites, les paramètres, les fichiers d'instances, les décisions prises ou encore les benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf837ae1-0ec8-4baf-8f77-65fb07015ca3",
   "metadata": {},
   "source": [
    "## **2. PROTOCOLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487d26f-5822-4f26-8286-a8b9711c74c4",
   "metadata": {},
   "source": [
    "#### **2.1. BENCHMARKS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500805c-b31b-4bf8-94f1-cfa57e3d4e0b",
   "metadata": {},
   "source": [
    "Les performances de notre algorithme sont évaluées sur un ensemble d'instances de référence, issus de trois **benchmarks** reconnus dans la littérature pour notre problème."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213932a-f1d0-4184-86e2-13a0b3282749",
   "metadata": {},
   "source": [
    "Un **benchmark** est un ensemble d'instances représentatives, pour lesquelles il existe à chaque fois une **meilleure solution connue** (Best Know Solution, **BKS**), c'est-à-dire la meilleure solution trouvée à ce jour par la communauté scientifique. Les BKS ne sont pas systématiquement les solutions optimales, mais elles permettent déjà de se situer, et ce par rapport aux meilleurs algorithmes existants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12913329-a3ab-4a6c-a4fd-563d8d61a299",
   "metadata": {},
   "source": [
    "Nous avons sélectionnés 3 benchmarks, tous reconnus dans la littérature pour notre problème et respectivement basés sur les instances issues de la bibliothèque **VRPLIB**, des instances **SOLOMON**, introduites par Solomon (1987), et des instances **HG**, introduites par Hommbeger et Gehring (1999)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1a714-5888-4cb2-90ba-e71c507f7a47",
   "metadata": {},
   "source": [
    "#### **2.2. INDICATEURS DE PERFORMANCE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1caf91a-1efd-4139-ad87-146e401cc847",
   "metadata": {},
   "source": [
    "Pour évaluer les résultats de notre algorithme, nous nous baserons sur plusieurs indicateurs.\n",
    "Pour mesurer la qualité, nous prendrons en compte la valeur de la fonction objectif, c'est-à-dire le coût total, et nous calculerons grâce à celle-ci l'écart relatif par rapport à la meilleure solution connue selon l'instance. Cet **écart à l'optimum**, exprimé en pourcentage, s'obtient avec la formule :\n",
    "$$\n",
    "Écart = \\frac{résultat - BKS}{BKS} \\times 100\n",
    "$$\n",
    "Pour mesurer la robustesse, chaque instance sera exécutée plusieurs fois. Nous analyserons ensuite la moyenne, l'écart-type et les extremums obtenus sur ces exécutions. En effet, de par la nature stochastique de notre méta-heuristique, on ne peut se contenter d'une seule exécution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632f772-547e-4cec-8092-6c54471f516b",
   "metadata": {},
   "source": [
    "#### **2.3. MÉTHODOLOGIE D'ANALYSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d807e6-1c2d-4fba-8ae3-712a961661f5",
   "metadata": {},
   "source": [
    "L'analyse des données est nécessaire pour répondre aux questions de recherche. C'est elle qui nous permet d'évaluer les forces et faiblesses de notre algorithme. Nous utiliserons principalement des outils issus des statistiques descriptives et des représentations graphiques. Les courbes de convergence nous seront particulièrement utiles pour montrer l'évolution de l'optimum trouvé au fur et à mesure du temps ou des itérations. Les boîtes à moustaches permettront de mieux visualiser les distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5a4d4-299a-4231-8eaa-7d67f6af5153",
   "metadata": {},
   "source": [
    "## **3. PLAN D'EXPÉRIENCE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df50ff-8a39-41e1-926e-74eb612a8005",
   "metadata": {},
   "source": [
    "Pour calibrer les **facteurs** de notre méta-heuristique, c'est-à-dire les paramètres de l'algorithme qui influent sur l'intensité des mécanismes implémentés, nous pouvons naïvement faire varier un seul paramètre à la fois jusqu'à obtenir un bon résultat. Cependant, cette méthode est à la fois extrêmement coûteuse en temps de calcul et incapable de détecter les interactions entre les paramètres. Il est fréquent que l'effet d'un paramètre dépende de la valeur d'un autre. C'est pourquoi nous mettons en place un plan d'expérience, avec l'objectif de trouver une configuration de facteurs globalement robuste et performante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a429c1ed-258e-4795-94d4-9c5dc954842c",
   "metadata": {},
   "source": [
    "#### **3.1. IDENTIFICATION DES FACTEURS ET DES NIVEAUX**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4cee9a-62e5-41ec-8001-3c908d7fd33c",
   "metadata": {},
   "source": [
    "La première étape consiste à lister les paramètres de notre méta-heuristique qui semblent avoir un impact sur sa performance. Ensuite, nous devons définir pour chaque facteur un ensemble de niveaux à tester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da6783-069e-44e9-ab9b-25dcbf0c450d",
   "metadata": {},
   "source": [
    "#### **3.2. CHOIX DU DESIGN EXPÉRIMENTAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8307b2ed-5392-44de-9e9e-4c9e0e771bdd",
   "metadata": {},
   "source": [
    "#### **3.3. EXÉCUTION ET ANALYSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c323eb-31d7-4aac-9d73-d40bb52bb09e",
   "metadata": {},
   "source": [
    "## **4. ANALYSE**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVRPTW Python 3.11 Venv",
   "language": "python",
   "name": "vrptw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
